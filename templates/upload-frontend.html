<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Audio Recorder</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background-color: #f0f0f0;
      margin: 0;
      padding: 20px;
    }
    
    .container {
      max-width: 800px;
      margin: 0 auto;
    }
    
    .language-selector {
      margin-bottom: 20px;
    }
    
    #language-dropdown {
      padding: 8px;
      border-radius: 4px;
      border: 1px solid #ccc;
      font-size: 16px;
      margin-left: 10px;
    }
    .device-selector {
    margin-bottom: 20px;
    }

    #device-dropdown {
    padding: 8px;
    border-radius: 4px;
    border: 1px solid #ccc;
    font-size: 16px;
    margin-left: 10px;
    min-width: 200px;
    }

    .refresh-devices-btn {
    padding: 6px 12px;
    border: 1px solid #ccc;
    border-radius: 4px;
    background-color: #f8f9fa;
    cursor: pointer;
    margin-left: 10px;
    font-size: 14px;
    }

    .refresh-devices-btn:hover {
    background-color: #e9ecef;
    }

    /* Add to stats grid - modify the existing .stats rule */
    .stats {
    background-color: white;
    border-radius: 8px;
    padding: 15px;
    margin-top: 20px;
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
    gap: 15px;
    }

    .recording-container {
      background-color: rgba(0, 0, 0, 0.7);
      border-radius: 8px;
      padding: 20px;
      margin-bottom: 20px;
      min-height: 100px;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
    }
    
    .status-text {
      color: white;
      font-size: 20px;
      text-align: center;
      line-height: 1.5;
      margin-bottom: 20px;
      animation: fadeIn 0.5s ease-in-out;
    }
    
    .recording-indicator {
      width: 20px;
      height: 20px;
      border-radius: 50%;
      background-color: #ff4444;
      margin-right: 10px;
      display: none;
    }
    
    .recording-indicator.active {
      display: inline-block;
      animation: pulse 1s infinite;
    }
    
    @keyframes pulse {
      0% { opacity: 1; }
      50% { opacity: 0.3; }
      100% { opacity: 1; }
    }
    
    @keyframes fadeIn {
      from { opacity: 0; }
      to { opacity: 1; }
    }
    
    .controls {
      display: flex;
      gap: 10px;
      align-items: center;
    }
    
    .control-button {
      padding: 12px 24px;
      border: none;
      border-radius: 6px;
      font-size: 16px;
      cursor: pointer;
      transition: background-color 0.3s;
    }
    
    .start-button {
      background-color: #4CAF50;
      color: white;
    }
    
    .start-button:hover {
      background-color: #45a049;
    }
    
    .start-button:disabled {
      background-color: #cccccc;
      cursor: not-allowed;
    }
    
    .stop-button {
      background-color: #f44336;
      color: white;
    }
    
    .stop-button:hover {
      background-color: #da190b;
    }
    
    .stop-button:disabled {
      background-color: #cccccc;
      cursor: not-allowed;
    }
    
    .instructions {
      text-align: center;
      color: #666;
      font-style: italic;
    }
    
    .stats {
      background-color: white;
      border-radius: 8px;
      padding: 15px;
      margin-top: 20px;
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
      gap: 15px;
    }
    
    .stat-item {
      text-align: center;
    }
    
    .stat-value {
      font-size: 24px;
      font-weight: bold;
      color: #333;
    }
    
    .stat-label {
      font-size: 14px;
      color: #666;
      margin-top: 5px;
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="language-selector">
      <label for="language-dropdown">üåê Source Language:</label>
      <select id="language-dropdown">
        {% for language in languages %}
        <option value="{{ language.code }}">{{ language.name }}</option>
        {% endfor %}
      </select>
    </div>
    <div class="device-selector">
      <label for="device-dropdown">üé§ Input Device:</label>
      <select id="device-dropdown">
        <option value="">Loading devices...</option>
      </select>
      <button id="refresh-devices" class="refresh-devices-btn" title="Refresh device list">üîÑ</button>
    </div>
    <div class="recording-container">
      <div id="status" class="status-text">Ready to record</div>
      <div class="controls">
        <div class="recording-indicator" id="recording-indicator"></div>
        <button id="start-button" class="control-button start-button">Start Recording</button>
        <button id="stop-button" class="control-button stop-button" disabled>Stop Recording</button>
        <button id="new-speech-button" class="control-button new-speech-button">New Speech</button>
        <button id="undo-new-speech-button" class="control-button undo-button" disabled>Undo New Speech</button>
      </div>
    </div>


    <div class="instructions">
      <p>Select your source language and click "Start Recording" to begin continuous audio capture.</p>
      <p>Audio will be automatically sent to the server in chunks for processing.</p>
    </div>

    <div class="stats">
      <div class="stat-item">
        <div id="chunks-sent" class="stat-value">0</div>
        <div class="stat-label">Chunks Sent</div>
      </div>
      <div class="stat-item">
        <div id="recording-time" class="stat-value">00:00</div>
        <div class="stat-label">Recording Time</div>
      </div>
      <div class="stat-item">
        <div id="upload-status" class="stat-value">Ready</div>
        <div class="stat-label">Upload Status</div>
      </div>
      <div class="stat-item">
        <div id="current-device" class="stat-value">None</div>
        <div class="stat-label">Current Device</div>
      </div>
      <div class="stat-item">
        <div id="device-status" class="stat-value">Ready</div>
        <div class="stat-label">Device Status</div>
      </div>
    </div>
  </div>
  <script>
    const CONFIG = {
      INTERACTIVELY_SHORTER_LENGTH: parseInt("{{ interactively_shorter_length }}", 5000), // 5000 ms
      CHUNK_DURATION: parseInt("{{ chunk_duration }}", 5000), // 5000 ms per chunk
      SAMPLE_RATE: 16000,
      CHANNELS: 1,
      BITS_PER_SAMPLE: 16,
      API_URL: "{{ api_base_url }}",
      API_KEY: "{{ api_key }}"
    };

    // Audio recording variables
    let mediaRecorder = null;
    let audioStream = null;
    let isRecording = false;
    let recordingStartTime = null;
    let recordingTimer = null;
    let headerChunk = null;
    let isHeaderCaptured = false;
    let sendChunkInterval = null;

    // Statistics
    let chunksSent = 0;

    // Speech ID management
    let currentSpeechId = `speech-${Date.now()}`;
    let speechIdHistory = [];
    let speechCounter = 1;

    // Audio device variables
    let availableDevices = [];
    let selectedDeviceId = null;

    // DOM elements
    const languageDropdown = document.getElementById('language-dropdown');
    const statusElement = document.getElementById('status');
    const startButton = document.getElementById('start-button');
    const stopButton = document.getElementById('stop-button');
    const newSpeechButton = document.getElementById('new-speech-button');
    const undoNewSpeechButton = document.getElementById('undo-new-speech-button');
    const recordingIndicator = document.getElementById('recording-indicator');
    const chunksSentElement = document.getElementById('chunks-sent');
    const recordingTimeElement = document.getElementById('recording-time');
    const uploadStatusElement = document.getElementById('upload-status');
    const deviceDropdown = document.getElementById('device-dropdown');
    const refreshDevicesButton = document.getElementById('refresh-devices');
    const currentDeviceElement = document.getElementById('current-device');
    const deviceStatusElement = document.getElementById('device-status');

    /**
     * Initialize the application
     */
    function initializeApp() {
      statusElement.textContent = `Current speech session: ${currentSpeechId}`;
      updateButtonStates();
      populateDeviceDropdown();
    }

    /**
     * Update button states based on current recording status
     */
    function updateButtonStates() {
      startButton.disabled = isRecording;
      stopButton.disabled = !isRecording;
      newSpeechButton.disabled = isRecording;
      deviceDropdown.disabled = isRecording;
      refreshDevicesButton.disabled = isRecording;
      // undoNewSpeechButton state is managed by speech functions
    }

    /**
     * Generate a new speech ID
     */
    function generateNewSpeechId() {
      speechCounter++;
      return `speech-${Date.now()}-${speechCounter}`;
    }

    /**
     * Create a new speech session
     */
    function createNewSpeech() {
      // Save current speech ID to history
      if (currentSpeechId) {
        speechIdHistory.push(currentSpeechId);
      }

      // Generate new speech ID
      currentSpeechId = generateNewSpeechId();

      // Update UI
      statusElement.textContent = `New speech session: ${currentSpeechId}`;
      undoNewSpeechButton.disabled = false;

      // Reset chunk counter for new speech
      chunksSent = 0;
      chunksSentElement.textContent = chunksSent;

      console.log(`Created new speech session: ${currentSpeechId}`);
    }

    /**
     * Undo the last new speech action
     */
    function undoNewSpeech() {
      if (speechIdHistory.length === 0) {
        statusElement.textContent = 'No previous speech to restore';
        return;
      }

      // Restore previous speech ID
      currentSpeechId = speechIdHistory.pop();

      // Update UI
      statusElement.textContent = `Restored speech session: ${currentSpeechId}`;

      // Disable undo button if no more history
      if (speechIdHistory.length === 0) {
        undoNewSpeechButton.disabled = true;
      }

      console.log(`Restored speech session: ${currentSpeechId}`);
    }

    /**
     * Get the currently selected language
     */
    function getSelectedLanguage() {
      return languageDropdown.value;
    }

    /**
     * Update the recording timer display
     */
    function updateRecordingTimer() {
      if (!recordingStartTime) return;

      const elapsed = Date.now() - recordingStartTime;
      const minutes = Math.floor(elapsed / 60000);
      const seconds = Math.floor((elapsed % 60000) / 1000);
      recordingTimeElement.textContent = `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
    }
    /**
     * Convert audio blob to 16-bit PCM format
     */
    async function convertToPCM(audioBlob) {
      console.log('üîÑ Converting audio to PCM...');

      return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onload = async function () {
          try {
            const audioContext = new AudioContext({
              sampleRate: CONFIG.SAMPLE_RATE
            });
            const audioBuffer = await audioContext.decodeAudioData(reader.result); // TODO: EncodingError: Unable to decode audio data

            console.log(`üìä Original: ${audioBuffer.sampleRate}Hz, ${audioBuffer.numberOfChannels}ch, ${audioBuffer.length} samples`);

            // Get mono channel and resample if needed
            let audioData = audioBuffer.getChannelData(0);
            if (audioBuffer.sampleRate !== CONFIG.SAMPLE_RATE) {
              audioData = resampleTo16kHz(audioData, audioBuffer.sampleRate);
            }

            // Convert to 16-bit PCM
            const pcmData = new Int16Array(audioData.length);
            for (let i = 0; i < audioData.length; i++) {
              const sample = Math.max(-1, Math.min(1, audioData[i]));
              pcmData[i] = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
            }

            console.log(`‚úÖ PCM: 16kHz, 1ch, ${pcmData.length} samples, ${pcmData.byteLength} bytes`);

            const pcmBlob = new Blob([pcmData.buffer], {
              type: 'audio/pcm'
            });
            resolve(pcmBlob);
          } catch (error) {
            console.error('‚ùå PCM conversion error:', error);
            reject(error);
          }
        };
        reader.readAsArrayBuffer(audioBlob);
      });
    }

    /**
     * Resample audio data to 16kHz
     */
    function resampleTo16kHz(audioData, originalSampleRate) {
      console.log(`üîÑ Resampling from ${originalSampleRate}Hz to 16kHz...`);

      const ratio = originalSampleRate / CONFIG.SAMPLE_RATE;
      const newLength = Math.round(audioData.length / ratio);
      const resampled = new Float32Array(newLength);

      for (let i = 0; i < newLength; i++) {
        const originalIndex = i * ratio;
        const index = Math.floor(originalIndex);
        const fraction = originalIndex - index;

        if (index + 1 < audioData.length) {
          resampled[i] = audioData[index] * (1 - fraction) + audioData[index + 1] * fraction;
        } else {
          resampled[i] = audioData[index] || 0;
        }
      }

      return resampled;
    }

    /**
     * Verify format and integrity of audio blob
     */
    async function verifyAudioBlob(audioBlob) {
      const verification = {
        isValid: false,
        size: audioBlob.size,
        type: audioBlob.type,
        hasHeader: false,
        canPlay: false,
        duration: null,
        errors: [],
        warnings: []
      };

      try {
        // Basic checks
        if (!audioBlob || audioBlob.size === 0) {
          verification.errors.push('Blob is empty or null');
          return verification;
        }

        if (!audioBlob.type) {
          verification.warnings.push('No MIME type specified');
        }

        // Size checks
        if (audioBlob.size < 100) {
          verification.warnings.push(`Very small blob size: ${audioBlob.size} bytes`);
        }

        // Read first few bytes to check for valid header
        const headerBytes = await readBlobBytes(audioBlob, 0, 32);
        const headerHex = Array.from(headerBytes).map(b => b.toString(16).padStart(2, '0')).join(' ');
        console.log(`üîç Header bytes: ${headerHex}`);

        // Check for WebM header signature
        if (audioBlob.type.includes('webm')) {
          // WebM files start with EBML header (0x1A 0x45 0xDF 0xA3)
          if (headerBytes[0] === 0x1A && headerBytes[1] === 0x45 &&
            headerBytes[2] === 0xDF && headerBytes[3] === 0xA3) {
            verification.hasHeader = true;
            console.log('‚úÖ Valid WebM header detected');
          } else {
            verification.warnings.push('WebM header signature not found');
          }
        }

        // Try to create audio element to test playability
        try {
          const audioUrl = URL.createObjectURL(audioBlob);
          const audio = new Audio(audioUrl);

          await new Promise((resolve, reject) => {
            const timeout = setTimeout(() => {
              reject(new Error('Audio load timeout'));
            }, 5000);

            audio.onloadedmetadata = () => {
              clearTimeout(timeout);
              verification.canPlay = true;
              verification.duration = audio.duration;
              console.log(`‚úÖ Audio is playable, duration: ${audio.duration}s`);
              URL.revokeObjectURL(audioUrl);
              resolve();
            };

            audio.onerror = (e) => {
              clearTimeout(timeout);
              verification.errors.push(`Audio load error: ${e.message || 'Unknown error'}`);
              URL.revokeObjectURL(audioUrl);
              reject(e);
            };

            audio.load();
          });
        } catch (audioError) {
          verification.warnings.push(`Could not verify playability: ${audioError.message}`);
        }

        // Check if blob appears to be corrupted (all zeros or repeated patterns)
        const sampleBytes = await readBlobBytes(audioBlob, Math.min(1000, audioBlob.size - 100), 100);
        const uniqueBytes = new Set(sampleBytes).size;
        if (uniqueBytes < 5) {
          verification.warnings.push('Blob may be corrupted (low byte diversity)');
        }

        // Overall validity assessment
        verification.isValid = verification.errors.length === 0 &&
          verification.size > 0 &&
          (verification.hasHeader || verification.canPlay);

      } catch (error) {
        verification.errors.push(`Verification failed: ${error.message}`);
      }

      return verification;
    }

    /**
     * Helper function to read specific bytes from a blob
     */
    async function readBlobBytes(blob, start, length) {
      const slice = blob.slice(start, start + length);
      const arrayBuffer = await slice.arrayBuffer();
      return new Uint8Array(arrayBuffer);
    }

    /**
     * Enhanced send function with verification
     */
    async function sendAudioChunk(audioBlob) {
      try {
        // Verify blob before sending
        console.log('üîç Verifying audio blob...');
        const verification = await verifyAudioBlob(audioBlob);

        // Log verification results
        console.log('üìã Blob Verification Results:', {
          isValid: verification.isValid,
          size: verification.size,
          type: verification.type,
          hasHeader: verification.hasHeader,
          canPlay: verification.canPlay,
          duration: verification.duration,
          errors: verification.errors,
          warnings: verification.warnings
        });

        // Handle verification results
        if (verification.errors.length > 0) {
          console.error('‚ùå Blob verification failed:', verification.errors);
          uploadStatusElement.textContent = 'Invalid Audio';
          uploadStatusElement.style.color = '#f44336';
          return;
        }

        if (verification.warnings.length > 0) {
          console.warn('‚ö†Ô∏è Blob verification warnings:', verification.warnings);
        }

        if (!verification.isValid) {
          console.warn('‚ö†Ô∏è Blob may be invalid, but attempting to send anyway');
        }

        // uploadStatusElement.textContent = 'Converting...';
        uploadStatusElement.style.color = '#ff9800';

        // const pcmBlob = await convertToPCM(audioBlob); // no conversion

        uploadStatusElement.textContent = 'Uploading...';

        // Detect file extension from blob type
        const getFileExtension = (mimeType) => {
          const mimeToExt = {
            'audio/webm': 'webm',
            'audio/webm;codecs=opus': 'webm',
            'audio/mp4': 'm4a',
            'audio/mpeg': 'mp3',
            'audio/wav': 'wav',
            'audio/ogg': 'ogg'
          };
          return mimeToExt[mimeType] || 'webm'; // fallback to webm
        };

        const extension = getFileExtension(audioBlob.type);
        const timestamp = Date.now();
        const filename = `audio_chunk_${timestamp}.${extension}`;

        const formData = new FormData();
        formData.append('sourceLanguage', getSelectedLanguage());
        formData.append('audio_file', audioBlob, filename);
        formData.append('sampleRate', CONFIG.SAMPLE_RATE.toString());
        formData.append('channels', CONFIG.CHANNELS.toString());
        formData.append('bitsPerSample', CONFIG.BITS_PER_SAMPLE.toString());
        formData.append('speech_id', currentSpeechId);
        formData.append('timestamp', timestamp.toString());

        // Enhanced logging with verification info
        console.log('üìã FormData contents:');
        console.log(`  Blob verification: ${verification.isValid ? '‚úÖ Valid' : '‚ö†Ô∏è Questionable'}`);
        for (let [key, value] of formData.entries()) {
          if (value instanceof Blob) {
            console.log(`  ${key}: Blob(${value.size} bytes, ${value.type})`);
          } else {
            console.log(`  ${key}: ${value}`);
          }
        }

        const response = await fetch(`${CONFIG.API_URL}/publish`, {
          method: 'POST',
          headers: {
            'x-api-key': CONFIG.API_KEY
          },
          body: formData,
        });

        if (response.ok) {
          chunksSent++;
          chunksSentElement.textContent = chunksSent;
          uploadStatusElement.textContent = 'Success';
          uploadStatusElement.style.color = '#4CAF50';

          const result = await response.json();
          console.log(`‚úÖ Audio chunk sent successfully for speech ${currentSpeechId}:`, result);
        } else {
          const errorText = await response.text();
          console.error('‚ùå API Error:', response.status, errorText);
          throw new Error(`HTTP ${response.status}: ${errorText}`);
        }
      } catch (error) {
        console.error('‚ùå Error processing/sending audio chunk:', error);
        uploadStatusElement.textContent = 'Error';
        uploadStatusElement.style.color = '#f44336';

        // Show more specific error messages
        if (error.message.includes('decodeAudioData')) {
          console.error('Audio decoding failed - check audio format');
        } else if (error.message.includes('HTTP')) {
          console.error('Server error - check API endpoint and key');
        }
      }

      // Reset upload status after 3 seconds
      setTimeout(() => {
        if (isRecording) {
          uploadStatusElement.textContent = 'Ready';
          uploadStatusElement.style.color = '#333';
        }
      }, 3000);
    }

    /**
     * Get available audio input devices
     */
    async function getAudioDevices() {
      try {
        deviceStatusElement.textContent = 'Loading...';
        deviceStatusElement.style.color = '#ff9800';

        // Request permission first to get device labels
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: true
        });
        stream.getTracks().forEach(track => track.stop());

        // Get all media devices
        const devices = await navigator.mediaDevices.enumerateDevices();
        availableDevices = devices.filter(device => device.kind === 'audioinput');

        deviceStatusElement.textContent = 'Ready';
        deviceStatusElement.style.color = '#4CAF50';

        return availableDevices;
      } catch (error) {
        console.error('Error getting audio devices:', error);
        deviceStatusElement.textContent = 'Error';
        deviceStatusElement.style.color = '#f44336';
        return [];
      }
    }

    /**
     * Populate device dropdown
     */
    async function populateDeviceDropdown() {
      const devices = await getAudioDevices();

      // Clear existing options
      deviceDropdown.innerHTML = '';

      if (devices.length === 0) {
        deviceDropdown.innerHTML = '<option value="">No devices found</option>';
        return;
      }

      // Add default option
      const defaultOption = document.createElement('option');
      defaultOption.value = '';
      defaultOption.textContent = 'Default Device';
      deviceDropdown.appendChild(defaultOption);

      // Add device options
      devices.forEach(device => {
        const option = document.createElement('option');
        option.value = device.deviceId;
        option.textContent = device.label || `Microphone ${device.deviceId.substr(0, 8)}...`;
        deviceDropdown.appendChild(option);
      });

      // Set current device display
      updateCurrentDeviceDisplay();
    }

    /**
     * Update current device display
     */
    function updateCurrentDeviceDisplay() {
      const selectedOption = deviceDropdown.options[deviceDropdown.selectedIndex];
      if (selectedOption) {
        currentDeviceElement.textContent = selectedOption.textContent;
      }
    }

    /**
     * Get selected device ID
     */
    function getSelectedDeviceId() {
      return deviceDropdown.value || null;
    }

    /**
     * Start continuous audio recording - UPDATED with comprehensive event handling
     */
    async function startRecording() {
      try {
        selectedDeviceId = getSelectedDeviceId();

        // Reset all state variables
        headerChunk = null;
        isHeaderCaptured = false;

        // Clear any existing interval
        if (sendChunkInterval) {
          clearInterval(sendChunkInterval);
          sendChunkInterval = null;
        }

        // Prepare audio constraints
        const audioConstraints = {
          sampleRate: CONFIG.SAMPLE_RATE,
          channelCount: CONFIG.CHANNELS,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        };

        if (selectedDeviceId) {
          audioConstraints.deviceId = {
            exact: selectedDeviceId
          };
        }

        // Request microphone access
        audioStream = await navigator.mediaDevices.getUserMedia({
          audio: audioConstraints
        });

        // Determine best supported MIME type
        const supportedTypes = [
          'audio/ogg', 
          'audio/webm;codecs=opus',
          'audio/webm',
          'audio/mp4',
          'audio/ogg;codecs=opus'
        ];

        let mimeType = 'audio/webm'; // fallback
        for (const type of supportedTypes) {
          if (MediaRecorder.isTypeSupported(type)) {
            mimeType = type;
            console.log(`‚úÖ Using MIME type: ${mimeType}`);
            break;
          }
        }

        // Create MediaRecorder with comprehensive options
        mediaRecorder = new MediaRecorder(audioStream, {
          mimeType: mimeType,
          audioBitsPerSecond: 128000
        });

        mediaRecorder.ondataavailable = async (event) => {
          console.log(`üéµ ondataavailable triggered - Size: ${event.data.size} bytes, Type: ${event.data.type}`);

          if (event.data.size === 0) {
            console.warn('‚ö†Ô∏è Received empty data chunk');
            return;
          }

          try {
            // much thanks to https://elixirforum.com/t/how-to-stream-audio-chunks-from-the-browser-to-the-server/66091/5
            // Filter out tiny chunks after header is captured
            if (headerChunk && event.data.size < 1000) {
              console.log(`üö´ Skipping tiny chunk: ${event.data.size} bytes`);
              return;
            }

            if (!isHeaderCaptured) {
              headerChunk = event.data;
              isHeaderCaptured = true;
              console.log(`üìã Header chunk captured: ${event.data.size} bytes, Type: ${event.data.type}`);
              return;
            } else {
              console.log(`üì¶ Processing audio chunk: ${event.data.size} bytes`);

              const chunkWithHeader = new Blob([headerChunk, event.data], {
                type: event.data.type
              });

              await sendAudioChunk(chunkWithHeader);
            }
          } catch (error) {
            console.error('‚ùå Error in ondataavailable:', error);
          }
        };

        mediaRecorder.onerror = (event) => {
          console.error('‚ùå MediaRecorder error:', event.error);
          statusElement.textContent = `Recording error: ${event.error?.message || 'Unknown error'}`;
        };

        mediaRecorder.onstart = () => {
          console.log('üé¨ MediaRecorder started');
        };

        mediaRecorder.onstop = () => {
          console.log('üõë MediaRecorder stopped');
        };

        mediaRecorder.onpause = () => {
          console.log('‚è∏Ô∏è MediaRecorder paused');
        };

        mediaRecorder.onresume = () => {
          console.log('‚ñ∂Ô∏è MediaRecorder resumed');
        };

        console.log('üé¨ Starting MediaRecorder...');
        mediaRecorder.start();

        const captureHeaderChunk = () => {
          if (mediaRecorder && mediaRecorder.state === 'recording') {
            if (!isHeaderCaptured) {
              console.log('üìã Requesting initial header chunk...');
              mediaRecorder.requestData();
              setTimeout(captureHeaderChunk, 50);
            } else {
              return;
            }
          } else {
            console.error('‚ùå MediaRecorder not in recording state for header request');
          }
        }
        setTimeout(captureHeaderChunk, 50);

        const startRegularChunks = () => {
          let attempts = 0;
          const maxAttempts = 50; // 5 seconds max wait
          let isFirstChunk = true;

          const checkHeaderAndStart = () => {
            attempts++;

            if (isHeaderCaptured) {
              console.log('üìã Header captured, starting regular chunk intervals');

              const scheduleNextChunk = () => {
                const chunkDuration = isFirstChunk 
                  ? (CONFIG.INTERACTIVELY_SHORTER_LENGTH)
                  : CONFIG.CHUNK_DURATION;
                
                console.log(`‚è∞ Scheduling ${isFirstChunk ? 'first' : 'subsequent'} chunk in ${chunkDuration}ms`);
                
                setTimeout(() => {
                  if (mediaRecorder && mediaRecorder.state === 'recording') {
                    console.log('üìã Requesting data chunk...');
                    mediaRecorder.requestData();
                    isFirstChunk = false;
                    scheduleNextChunk(); // Schedule the next chunk
                  } else {
                    console.warn('‚ö†Ô∏è MediaRecorder not recording, stopping chunk scheduling');
                  }
                }, chunkDuration);
              };

              scheduleNextChunk(); // Start the scheduling

            } else if (attempts < maxAttempts) {
              console.log(`‚è≥ Waiting for header... (attempt ${attempts}/${maxAttempts})`);
              setTimeout(checkHeaderAndStart, 100);
            } else {
              console.error('‚ùå Header chunk timeout - forcing regular chunks anyway');
              // Force stop recording and show error state
              stopRecording()
              deviceStatusElement.textContent = 'Error';
              deviceStatusElement.style.color = '#f44336';
            }
          };

          checkHeaderAndStart();
        };

        // Start regular chunk timing
        setTimeout(startRegularChunks, 200);

        // Update UI
        isRecording = true;
        recordingStartTime = Date.now();
        updateButtonStates();
        recordingIndicator.classList.add('active');
        statusElement.textContent = `Recording... (${mimeType})`;
        deviceStatusElement.textContent = 'Recording';
        deviceStatusElement.style.color = '#ff4444';

        // Start timer
        recordingTimer = setInterval(updateRecordingTimer, 1000);

        console.log(`‚úÖ Recording started with MIME type: ${mimeType}`);

      } catch (error) {
        console.error('‚ùå Error starting recording:', error);
      }
    }

    /**
     * Stop continuous audio recording - UPDATED with better cleanup
     */
    function stopRecording() {
      console.log('üõë Stopping recording...');

      // Clear chunk interval first
      if (sendChunkInterval) {
        clearInterval(sendChunkInterval);
        sendChunkInterval = null;
        console.log('‚úÖ Chunk interval cleared');
      }

      if (mediaRecorder && isRecording) {
        // Check MediaRecorder state before stopping
        console.log(`üìä MediaRecorder state before stop: ${mediaRecorder.state}`);

        // Request final data before stopping
        if (mediaRecorder.state === 'recording') {
          console.log('üìã Requesting final data chunk...');
          mediaRecorder.requestData();
        }

        // Stop after a brief delay to allow final data
        setTimeout(() => {
          if (mediaRecorder && (mediaRecorder.state === 'recording' || mediaRecorder.state === 'paused')) {
            mediaRecorder.stop();
          }
          audioStream.getTracks().forEach(track => {
            track.stop();
            console.log('üîá Audio track stopped');
          });
          audioStream = null;
          mediaRecorder = null;
          headerChunk = null;
          isHeaderCaptured = false;
        }, 100);

        // Update UI
        isRecording = false;
        recordingStartTime = null;
        updateButtonStates();
        recordingIndicator.classList.remove('active');
        statusElement.textContent = 'Recording stopped';
        deviceStatusElement.textContent = 'Ready';
        deviceStatusElement.style.color = '#333';

        // Clear timer
        if (recordingTimer) {
          clearInterval(recordingTimer);
          recordingTimer = null;
        }

        // Reset upload status
        uploadStatusElement.textContent = 'Ready';
        uploadStatusElement.style.color = '#333';

        console.log('‚úÖ Recording stopped and state reset');
      }
    }

    /**
     * Reset statistics when language changes - UPDATED to reset header state
     */
    function handleLanguageChange() {
      if (isRecording) {
        stopRecording();
      }

      // Reset header state
      headerChunk = null;
      isHeaderCaptured = false;

      // Reset stats
      chunksSent = 0;
      chunksSentElement.textContent = '0';
      recordingTimeElement.textContent = '00:00';
      uploadStatusElement.textContent = 'Ready';
      uploadStatusElement.style.color = '#333';
      deviceStatusElement.textContent = 'Ready';
      deviceStatusElement.style.color = '#333';
      statusElement.textContent = 'Ready to record';
    }

    /**
     * Handle device selection change - UPDATED to reset header state
     */
    function handleDeviceChange() {
      updateCurrentDeviceDisplay();

      if (isRecording) {
        // Stop and restart recording with new device
        stopRecording();
        setTimeout(() => {
          startRecording();
        }, 500);
      }
    }

    /**
     * Handle device refresh
     */
    function handleDeviceRefresh() {
      if (!isRecording) {
        populateDeviceDropdown();
      }
    }

    /**
     * Handle device list changes
     */
    function handleDeviceListChange() {
      if (!isRecording) {
        console.log('Audio devices changed, refreshing list...');
        populateDeviceDropdown();
      }
    }

    /**
     * Handle new speech creation
     */
    function handleNewSpeech() {
      if (!isRecording) {
        createNewSpeech();
      }
    }

    /**
     * Handle undo new speech
     */
    function handleUndoNewSpeech() {
      if (!isRecording) {
        undoNewSpeech();
      }
    }

    /**
     * Handle page unload
     */
    function handlePageUnload() {
      if (isRecording) {
        stopRecording();
      }
    }

    // Event listeners
    startButton.addEventListener('click', startRecording);
    stopButton.addEventListener('click', stopRecording);
    newSpeechButton.addEventListener('click', handleNewSpeech);
    undoNewSpeechButton.addEventListener('click', handleUndoNewSpeech);
    languageDropdown.addEventListener('change', handleLanguageChange);
    deviceDropdown.addEventListener('change', handleDeviceChange);
    refreshDevicesButton.addEventListener('click', handleDeviceRefresh);
    window.addEventListener('beforeunload', handlePageUnload);

    // Listen for device changes
    if (navigator.mediaDevices) {
      navigator.mediaDevices.addEventListener('devicechange', handleDeviceListChange);
    }

    // Initialize application
    document.addEventListener('DOMContentLoaded', initializeApp);

    // Handle immediate execution for browsers that don't fire DOMContentLoaded
    if (document.readyState !== 'loading') {
      initializeApp();
    }

    // Check for browser support - UPDATED
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      document.addEventListener('DOMContentLoaded', () => {
        statusElement.textContent = 'Error: Browser does not support audio recording';
        startButton.disabled = true;
      });
    } else if (!window.AudioContext && !window.webkitAudioContext) {
      document.addEventListener('DOMContentLoaded', () => {
        statusElement.textContent = 'Error: Browser does not support audio processing';
        startButton.disabled = true;
      });
    }
  </script>

</body>
</html>
