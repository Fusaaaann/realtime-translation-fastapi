<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Audio Recorder</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background-color: #f0f0f0;
      margin: 0;
      padding: 20px;
    }
    
    .container {
      max-width: 800px;
      margin: 0 auto;
    }
    
    .language-selector {
      margin-bottom: 20px;
    }
    
    #language-dropdown {
      padding: 8px;
      border-radius: 4px;
      border: 1px solid #ccc;
      font-size: 16px;
      margin-left: 10px;
    }
    .device-selector {
    margin-bottom: 20px;
    }

    #device-dropdown {
    padding: 8px;
    border-radius: 4px;
    border: 1px solid #ccc;
    font-size: 16px;
    margin-left: 10px;
    min-width: 200px;
    }

    .refresh-devices-btn {
    padding: 6px 12px;
    border: 1px solid #ccc;
    border-radius: 4px;
    background-color: #f8f9fa;
    cursor: pointer;
    margin-left: 10px;
    font-size: 14px;
    }

    .refresh-devices-btn:hover {
    background-color: #e9ecef;
    }

    /* Add to stats grid - modify the existing .stats rule */
    .stats {
    background-color: white;
    border-radius: 8px;
    padding: 15px;
    margin-top: 20px;
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
    gap: 15px;
    }

    .recording-container {
      background-color: rgba(0, 0, 0, 0.7);
      border-radius: 8px;
      padding: 20px;
      margin-bottom: 20px;
      min-height: 100px;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
    }
    
    .status-text {
      color: white;
      font-size: 20px;
      text-align: center;
      line-height: 1.5;
      margin-bottom: 20px;
      animation: fadeIn 0.5s ease-in-out;
    }
    
    .recording-indicator {
      width: 20px;
      height: 20px;
      border-radius: 50%;
      background-color: #ff4444;
      margin-right: 10px;
      display: none;
    }
    
    .recording-indicator.active {
      display: inline-block;
      animation: pulse 1s infinite;
    }
    
    @keyframes pulse {
      0% { opacity: 1; }
      50% { opacity: 0.3; }
      100% { opacity: 1; }
    }
    
    @keyframes fadeIn {
      from { opacity: 0; }
      to { opacity: 1; }
    }
    
    .controls {
      display: flex;
      gap: 10px;
      align-items: center;
    }
    
    .control-button {
      padding: 12px 24px;
      border: none;
      border-radius: 6px;
      font-size: 16px;
      cursor: pointer;
      transition: background-color 0.3s;
    }
    
    .start-button {
      background-color: #4CAF50;
      color: white;
    }
    
    .start-button:hover {
      background-color: #45a049;
    }
    
    .start-button:disabled {
      background-color: #cccccc;
      cursor: not-allowed;
    }
    
    .stop-button {
      background-color: #f44336;
      color: white;
    }
    
    .stop-button:hover {
      background-color: #da190b;
    }
    
    .stop-button:disabled {
      background-color: #cccccc;
      cursor: not-allowed;
    }
    
    .instructions {
      text-align: center;
      color: #666;
      font-style: italic;
    }
    
    .stats {
      background-color: white;
      border-radius: 8px;
      padding: 15px;
      margin-top: 20px;
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
      gap: 15px;
    }
    
    .stat-item {
      text-align: center;
    }
    
    .stat-value {
      font-size: 24px;
      font-weight: bold;
      color: #333;
    }
    
    .stat-label {
      font-size: 14px;
      color: #666;
      margin-top: 5px;
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="language-selector">
      <label for="language-dropdown">üåê Source Language:</label>
      <select id="language-dropdown">
        {% for language in languages %}
        <option value="{{ language.code }}">{{ language.name }}</option>
        {% endfor %}
      </select>
    </div>
    <div class="device-selector">
      <label for="device-dropdown">üé§ Input Device:</label>
      <select id="device-dropdown">
        <option value="">Loading devices...</option>
      </select>
      <button id="refresh-devices" class="refresh-devices-btn" title="Refresh device list">üîÑ</button>
    </div>
    <div class="recording-container">
      <div id="status" class="status-text">Ready to record</div>
      <div class="controls">
        <div class="recording-indicator" id="recording-indicator"></div>
        <button id="start-button" class="control-button start-button">Start Recording</button>
        <button id="stop-button" class="control-button stop-button" disabled>Stop Recording</button>
        <button id="new-speech-button" class="control-button new-speech-button">New Speech</button>
        <button id="undo-new-speech-button" class="control-button undo-button" disabled>Undo New Speech</button>
      </div>
    </div>


    <div class="instructions">
      <p>Select your source language and click "Start Recording" to begin continuous audio capture.</p>
      <p>Audio will be automatically sent to the server in chunks for processing.</p>
    </div>

    <div class="stats">
      <div class="stat-item">
        <div id="chunks-sent" class="stat-value">0</div>
        <div class="stat-label">Chunks Sent</div>
      </div>
      <div class="stat-item">
        <div id="recording-time" class="stat-value">00:00</div>
        <div class="stat-label">Recording Time</div>
      </div>
      <div class="stat-item">
        <div id="upload-status" class="stat-value">Ready</div>
        <div class="stat-label">Upload Status</div>
      </div>
      <div class="stat-item">
        <div id="current-device" class="stat-value">None</div>
        <div class="stat-label">Current Device</div>
      </div>
      <div class="stat-item">
        <div id="device-status" class="stat-value">Ready</div>
        <div class="stat-label">Device Status</div>
      </div>
    </div>
  </div>
  <script>
    const CONFIG = {
      CHUNK_DURATION: 5000, // 5 seconds per chunk
      SAMPLE_RATE: 16000,
      CHANNELS: 1,
      BITS_PER_SAMPLE: 16,
      API_URL: "{{ api_base_url }}",
      API_KEY: "{{ api_key }}"
    };

    // Audio recording variables
    let mediaRecorder = null;
    let audioStream = null;
    let isRecording = false;
    let recordingStartTime = null;
    let recordingTimer = null;

    // Statistics
    let chunksSent = 0;

    // Speech ID management
    let currentSpeechId = `speech-${Date.now()}`;
    let speechIdHistory = [];
    let speechCounter = 1;

    // Audio device variables
    let availableDevices = [];
    let selectedDeviceId = null;

    // DOM elements
    const languageDropdown = document.getElementById('language-dropdown');
    const statusElement = document.getElementById('status');
    const startButton = document.getElementById('start-button');
    const stopButton = document.getElementById('stop-button');
    const newSpeechButton = document.getElementById('new-speech-button');
    const undoNewSpeechButton = document.getElementById('undo-new-speech-button');
    const recordingIndicator = document.getElementById('recording-indicator');
    const chunksSentElement = document.getElementById('chunks-sent');
    const recordingTimeElement = document.getElementById('recording-time');
    const uploadStatusElement = document.getElementById('upload-status');
    const deviceDropdown = document.getElementById('device-dropdown');
    const refreshDevicesButton = document.getElementById('refresh-devices');
    const currentDeviceElement = document.getElementById('current-device');
    const deviceStatusElement = document.getElementById('device-status');

    /**
     * Initialize the application
     */
    function initializeApp() {
      statusElement.textContent = `Current speech session: ${currentSpeechId}`;
      updateButtonStates();
      populateDeviceDropdown();
    }

    /**
     * Update button states based on current recording status
     */
    function updateButtonStates() {
      startButton.disabled = isRecording;
      stopButton.disabled = !isRecording;
      newSpeechButton.disabled = isRecording;
      deviceDropdown.disabled = isRecording;
      refreshDevicesButton.disabled = isRecording;
      // undoNewSpeechButton state is managed by speech functions
    }

    /**
     * Generate a new speech ID
     */
    function generateNewSpeechId() {
      speechCounter++;
      return `speech-${Date.now()}-${speechCounter}`;
    }

    /**
     * Create a new speech session
     */
    function createNewSpeech() {
      // Save current speech ID to history
      if (currentSpeechId) {
        speechIdHistory.push(currentSpeechId);
      }

      // Generate new speech ID
      currentSpeechId = generateNewSpeechId();

      // Update UI
      statusElement.textContent = `New speech session: ${currentSpeechId}`;
      undoNewSpeechButton.disabled = false;

      // Reset chunk counter for new speech
      chunksSent = 0;
      chunksSentElement.textContent = chunksSent;

      console.log(`Created new speech session: ${currentSpeechId}`);
    }

    /**
     * Undo the last new speech action
     */
    function undoNewSpeech() {
      if (speechIdHistory.length === 0) {
        statusElement.textContent = 'No previous speech to restore';
        return;
      }

      // Restore previous speech ID
      currentSpeechId = speechIdHistory.pop();

      // Update UI
      statusElement.textContent = `Restored speech session: ${currentSpeechId}`;

      // Disable undo button if no more history
      if (speechIdHistory.length === 0) {
        undoNewSpeechButton.disabled = true;
      }

      console.log(`Restored speech session: ${currentSpeechId}`);
    }

    /**
     * Get the currently selected language
     */
    function getSelectedLanguage() {
      return languageDropdown.value;
    }

    /**
     * Update the recording timer display
     */
    function updateRecordingTimer() {
      if (!recordingStartTime) return;

      const elapsed = Date.now() - recordingStartTime;
      const minutes = Math.floor(elapsed / 60000);
      const seconds = Math.floor((elapsed % 60000) / 1000);
      recordingTimeElement.textContent = `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
    }
    /**
     * Convert audio blob to 16-bit PCM format
     */
    async function convertToPCM(audioBlob) {
      console.log('üîÑ Converting audio to PCM...');

      return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onload = async function () {
          try {
            const audioContext = new AudioContext({
              sampleRate: CONFIG.SAMPLE_RATE
            });
            const audioBuffer = await audioContext.decodeAudioData(reader.result);

            console.log(`üìä Original: ${audioBuffer.sampleRate}Hz, ${audioBuffer.numberOfChannels}ch, ${audioBuffer.length} samples`);

            // Get mono channel and resample if needed
            let audioData = audioBuffer.getChannelData(0);
            if (audioBuffer.sampleRate !== CONFIG.SAMPLE_RATE) {
              audioData = resampleTo16kHz(audioData, audioBuffer.sampleRate);
            }

            // Convert to 16-bit PCM
            const pcmData = new Int16Array(audioData.length);
            for (let i = 0; i < audioData.length; i++) {
              const sample = Math.max(-1, Math.min(1, audioData[i]));
              pcmData[i] = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
            }

            console.log(`‚úÖ PCM: 16kHz, 1ch, ${pcmData.length} samples, ${pcmData.byteLength} bytes`);

            const pcmBlob = new Blob([pcmData.buffer], {
              type: 'audio/pcm'
            });
            resolve(pcmBlob);
          } catch (error) {
            console.error('‚ùå PCM conversion error:', error);
            reject(error);
          }
        };
        reader.readAsArrayBuffer(audioBlob);
      });
    }

    /**
     * Resample audio data to 16kHz
     */
    function resampleTo16kHz(audioData, originalSampleRate) {
      console.log(`üîÑ Resampling from ${originalSampleRate}Hz to 16kHz...`);

      const ratio = originalSampleRate / CONFIG.SAMPLE_RATE;
      const newLength = Math.round(audioData.length / ratio);
      const resampled = new Float32Array(newLength);

      for (let i = 0; i < newLength; i++) {
        const originalIndex = i * ratio;
        const index = Math.floor(originalIndex);
        const fraction = originalIndex - index;

        if (index + 1 < audioData.length) {
          resampled[i] = audioData[index] * (1 - fraction) + audioData[index + 1] * fraction;
        } else {
          resampled[i] = audioData[index] || 0;
        }
      }

      return resampled;
    }

    /**
     * Send audio chunk to the server - UPDATED with PCM conversion
     */
    async function sendAudioChunk(audioBlob) {
      try {
        uploadStatusElement.textContent = 'Converting...';
        uploadStatusElement.style.color = '#ff9800';

        // Convert to PCM first
        const pcmBlob = await convertToPCM(audioBlob);

        uploadStatusElement.textContent = 'Uploading...';

        const formData = new FormData();
        formData.append('sourceLanguage', getSelectedLanguage());
        formData.append('audio_file', pcmBlob, 'audio_chunk.pcm'); // Changed filename and blob
        formData.append('sampleRate', CONFIG.SAMPLE_RATE.toString());
        formData.append('channels', CONFIG.CHANNELS.toString()); // Added
        formData.append('bitsPerSample', CONFIG.BITS_PER_SAMPLE.toString()); // Added
        formData.append('speech_id', currentSpeechId);

        // Log what we're sending for debugging
        console.log('üìã FormData contents:');
        for (let [key, value] of formData.entries()) {
          if (value instanceof Blob) {
            console.log(`  ${key}: Blob(${value.size} bytes, ${value.type})`);
          } else {
            console.log(`  ${key}: ${value}`);
          }
        }

        const response = await fetch(`${CONFIG.API_URL}/publish`, { // Updated to use CONFIG
          method: 'POST',
          headers: {
            'x-api-key': CONFIG.API_KEY // Updated to use CONFIG
          },
          body: formData,
        });

        if (response.ok) {
          chunksSent++;
          chunksSentElement.textContent = chunksSent;
          uploadStatusElement.textContent = 'Success';
          uploadStatusElement.style.color = '#4CAF50';

          const result = await response.json();
          console.log(`‚úÖ PCM chunk sent successfully for speech ${currentSpeechId}:`, result);
        } else {
          const errorText = await response.text();
          console.error('‚ùå API Error:', response.status, errorText);
          throw new Error(`HTTP ${response.status}: ${errorText}`);
        }
      } catch (error) {
        console.error('‚ùå Error processing/sending audio chunk:', error);
        uploadStatusElement.textContent = 'Error';
        uploadStatusElement.style.color = '#f44336';

        // Show more specific error messages
        if (error.message.includes('decodeAudioData')) {
          console.error('Audio decoding failed - check audio format');
        } else if (error.message.includes('HTTP')) {
          console.error('Server error - check API endpoint and key');
        }
      }

      // Reset upload status after 3 seconds (increased for PCM processing time)
      setTimeout(() => {
        if (isRecording) {
          uploadStatusElement.textContent = 'Ready';
          uploadStatusElement.style.color = '#333';
        }
      }, 3000); // Increased from 2000
    }

    /**
     * Get available audio input devices
     */
    async function getAudioDevices() {
      try {
        deviceStatusElement.textContent = 'Loading...';
        deviceStatusElement.style.color = '#ff9800';

        // Request permission first to get device labels
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: true
        });
        stream.getTracks().forEach(track => track.stop());

        // Get all media devices
        const devices = await navigator.mediaDevices.enumerateDevices();
        availableDevices = devices.filter(device => device.kind === 'audioinput');

        deviceStatusElement.textContent = 'Ready';
        deviceStatusElement.style.color = '#4CAF50';

        return availableDevices;
      } catch (error) {
        console.error('Error getting audio devices:', error);
        deviceStatusElement.textContent = 'Error';
        deviceStatusElement.style.color = '#f44336';
        return [];
      }
    }

    /**
     * Populate device dropdown
     */
    async function populateDeviceDropdown() {
      const devices = await getAudioDevices();

      // Clear existing options
      deviceDropdown.innerHTML = '';

      if (devices.length === 0) {
        deviceDropdown.innerHTML = '<option value="">No devices found</option>';
        return;
      }

      // Add default option
      const defaultOption = document.createElement('option');
      defaultOption.value = '';
      defaultOption.textContent = 'Default Device';
      deviceDropdown.appendChild(defaultOption);

      // Add device options
      devices.forEach(device => {
        const option = document.createElement('option');
        option.value = device.deviceId;
        option.textContent = device.label || `Microphone ${device.deviceId.substr(0, 8)}...`;
        deviceDropdown.appendChild(option);
      });

      // Set current device display
      updateCurrentDeviceDisplay();
    }

    /**
     * Update current device display
     */
    function updateCurrentDeviceDisplay() {
      const selectedOption = deviceDropdown.options[deviceDropdown.selectedIndex];
      if (selectedOption) {
        currentDeviceElement.textContent = selectedOption.textContent;
      }
    }

    /**
     * Get selected device ID
     */
    function getSelectedDeviceId() {
      return deviceDropdown.value || null;
    }

    /**
     * Start continuous audio recording - UPDATED with better audio constraints
     */
    async function startRecording() {
      try {
        selectedDeviceId = getSelectedDeviceId();

        // Prepare audio constraints - UPDATED
        const audioConstraints = {
          sampleRate: CONFIG.SAMPLE_RATE, // Use CONFIG
          channelCount: CONFIG.CHANNELS, // Use CONFIG
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true // Added for better audio quality
        };

        // Add device ID if specified
        if (selectedDeviceId) {
          audioConstraints.deviceId = {
            exact: selectedDeviceId
          };
        }

        // Request microphone access
        audioStream = await navigator.mediaDevices.getUserMedia({
          audio: audioConstraints
        });

        // Create MediaRecorder - UPDATED with better options
        const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus') ?
          'audio/webm;codecs=opus' :
          'audio/webm';

        mediaRecorder = new MediaRecorder(audioStream, {
          mimeType: mimeType,
          audioBitsPerSecond: 128000 // Added for consistent quality
        });

        // Handle data available event
        mediaRecorder.ondataavailable = async (event) => { // Made async
          if (event.data.size > 0) {
            console.log(`üì¶ Received audio chunk: ${event.data.size} bytes`);
            await sendAudioChunk(event.data); // Added await
          }
        };

        // Handle recording errors
        mediaRecorder.onerror = (event) => {
          console.error('‚ùå MediaRecorder error:', event.error);
          statusElement.textContent = 'Recording error occurred';
        };

        // Start recording with time slicing
        mediaRecorder.start(CONFIG.CHUNK_DURATION); // Use CONFIG

        // Update UI
        isRecording = true;
        recordingStartTime = Date.now();
        updateButtonStates();
        recordingIndicator.classList.add('active');
        statusElement.textContent = `Recording... (PCM ${CONFIG.SAMPLE_RATE}Hz)`; // Updated message
        deviceStatusElement.textContent = 'Recording';
        deviceStatusElement.style.color = '#ff4444';

        // Start timer
        recordingTimer = setInterval(updateRecordingTimer, 1000);

        console.log(`‚úÖ Recording started with PCM conversion (${CONFIG.CHUNK_DURATION}ms chunks)`);

      } catch (error) {
        console.error('‚ùå Error starting recording:', error);
        let errorMessage = 'Error: Could not access microphone';

        if (error.name === 'OverconstrainedError' || error.name === 'ConstraintNotSatisfiedError') {
          errorMessage = 'Error: Selected device not available';
          deviceStatusElement.textContent = 'Unavailable';
          deviceStatusElement.style.color = '#f44336';
        } else if (error.name === 'NotAllowedError') {
          errorMessage = 'Error: Microphone permission denied';
        }

        statusElement.textContent = errorMessage;
        alert(errorMessage + '. Please check permissions and device availability.');
      }
    }

    /**
     * Stop continuous audio recording
     */
    function stopRecording() {
      if (mediaRecorder && isRecording) {
        mediaRecorder.stop();

        // Stop all audio tracks
        if (audioStream) {
          audioStream.getTracks().forEach(track => track.stop());
        }

        // Update UI
        isRecording = false;
        recordingStartTime = null;
        updateButtonStates();
        recordingIndicator.classList.remove('active');
        statusElement.textContent = 'Recording stopped';
        deviceStatusElement.textContent = 'Ready';
        deviceStatusElement.style.color = '#333';

        // Clear timer
        if (recordingTimer) {
          clearInterval(recordingTimer);
          recordingTimer = null;
        }

        // Reset upload status
        uploadStatusElement.textContent = 'Ready';
        uploadStatusElement.style.color = '#333';
      }
    }

    /**
     * Reset statistics when language changes
     */
    function handleLanguageChange() {
      if (isRecording) {
        stopRecording();
      }

      // Reset stats
      chunksSent = 0;
      chunksSentElement.textContent = '0';
      recordingTimeElement.textContent = '00:00';
      uploadStatusElement.textContent = 'Ready';
      uploadStatusElement.style.color = '#333';
      deviceStatusElement.textContent = 'Ready';
      deviceStatusElement.style.color = '#333';
      statusElement.textContent = 'Ready to record';
    }

    /**
     * Handle device selection change
     */
    function handleDeviceChange() {
      updateCurrentDeviceDisplay();

      if (isRecording) {
        // Stop and restart recording with new device
        stopRecording();
        setTimeout(() => {
          startRecording();
        }, 500);
      }
    }

    /**
     * Handle device refresh
     */
    function handleDeviceRefresh() {
      if (!isRecording) {
        populateDeviceDropdown();
      }
    }

    /**
     * Handle device list changes
     */
    function handleDeviceListChange() {
      if (!isRecording) {
        console.log('Audio devices changed, refreshing list...');
        populateDeviceDropdown();
      }
    }

    /**
     * Handle new speech creation
     */
    function handleNewSpeech() {
      if (!isRecording) {
        createNewSpeech();
      }
    }

    /**
     * Handle undo new speech
     */
    function handleUndoNewSpeech() {
      if (!isRecording) {
        undoNewSpeech();
      }
    }

    /**
     * Handle page unload
     */
    function handlePageUnload() {
      if (isRecording) {
        stopRecording();
      }
    }

    // Event listeners
    startButton.addEventListener('click', startRecording);
    stopButton.addEventListener('click', stopRecording);
    newSpeechButton.addEventListener('click', handleNewSpeech);
    undoNewSpeechButton.addEventListener('click', handleUndoNewSpeech);
    languageDropdown.addEventListener('change', handleLanguageChange);
    deviceDropdown.addEventListener('change', handleDeviceChange);
    refreshDevicesButton.addEventListener('click', handleDeviceRefresh);
    window.addEventListener('beforeunload', handlePageUnload);

    // Listen for device changes
    if (navigator.mediaDevices) {
      navigator.mediaDevices.addEventListener('devicechange', handleDeviceListChange);
    }

    // Initialize application
    document.addEventListener('DOMContentLoaded', initializeApp);

    // Handle immediate execution for browsers that don't fire DOMContentLoaded
    if (document.readyState !== 'loading') {
      initializeApp();
    }

    // Check for browser support - UPDATED
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      document.addEventListener('DOMContentLoaded', () => {
        statusElement.textContent = 'Error: Browser does not support audio recording';
        startButton.disabled = true;
      });
    } else if (!window.AudioContext && !window.webkitAudioContext) {
      document.addEventListener('DOMContentLoaded', () => {
        statusElement.textContent = 'Error: Browser does not support audio processing';
        startButton.disabled = true;
      });
    }
  </script>

</body>
</html>
