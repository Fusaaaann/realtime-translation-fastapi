<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Seamless Audio & Caption Playback</title>
  <style>
    /* Simple style for the caption display */
    #caption {
      font-size: 1.5em;
      text-align: center;
      margin-top: 20px;
      padding: 10px;
      background: #f4f4f4;
      border-radius: 4px;
      width: 80%;
      margin-left: auto;
      margin-right: auto;
    }
  </style>
</head>
<body>
  <div id="caption">Captions will appear here</div>

  <script>
    // Create an AudioContext
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    let nextPlayTime = audioContext.currentTime; // time when the next audio segment should play

    // Polling interval in milliseconds (adjust as needed)
    const pollInterval = 3000;

    // Maintain last received timestamp so we only fetch new data
    let lastAudioTimestamp = 0;
    let lastCaptionTimestamp = 0;

    /**
     * Poll the /audio/translated-voice endpoint for new audio segments.
     * Each segment is expected to be an object with a "timestamp" and an "audio" field (base64 encoded MP3).
     */
    async function pollAudio() {
      try {
        // Adjust URL parameters as needed (here we use lang=ENGLISH)
        const response = await fetch(`/audio/translated-voice?lang=ENGLISH&timestamp=${lastAudioTimestamp}`);
        if (!response.ok) {
          throw new Error("Audio fetch error");
        }
        const audioSegments = await response.json();

        // Process each new segment
        for (const segment of audioSegments) {
          // Update lastAudioTimestamp to avoid fetching these segments again.
          if (segment.timestamp > lastAudioTimestamp) {
            lastAudioTimestamp = segment.timestamp;
          }
          // Convert the base64 audio data into an ArrayBuffer.
          const base64String = segment.audio;
          const binaryString = atob(base64String);
          const len = binaryString.length;
          const bytes = new Uint8Array(len);
          for (let i = 0; i < len; i++) {
            bytes[i] = binaryString.charCodeAt(i);
          }

          // Decode the audio data and schedule it for playback.
          audioContext.decodeAudioData(bytes.buffer, (decodedData) => {
            // Create a buffer source node.
            const source = audioContext.createBufferSource();
            source.buffer = decodedData;
            source.connect(audioContext.destination);

            // If nextPlayTime is in the past, adjust it to play slightly in the future for seamless playback.
            let startTime = nextPlayTime;
            const now = audioContext.currentTime;
            if (startTime < now) {
              startTime = now + 0.1;
            }
            source.start(startTime);
            // Update nextPlayTime for subsequent segments.
            nextPlayTime = startTime + decodedData.duration;
          }, (error) => {
            console.error("Error decoding audio", error);
          });
        }
      } catch (err) {
        console.error("Error fetching audio segments:", err);
      }
    }

    /**
     * Poll the /captions/translated endpoint for new captions.
     * The endpoint returns an array of caption objects, each with a "timestamp" and "text" field.
     */
    async function pollCaptions() {
      try {
        // Adjust URL parameters as needed (here we use lang=ENGLISH)
        const response = await fetch(`/captions/translated?lang=ENGLISH&timestamp=${lastCaptionTimestamp}`);
        if (!response.ok) {
          throw new Error("Caption fetch error");
        }
        const captions = await response.json();

        // If new captions are returned, update the display.
        if (captions.length > 0) {
          // For simplicity, display the latest caption.
          const latestCaption = captions[captions.length - 1];
          lastCaptionTimestamp = latestCaption.timestamp;
          document.getElementById("caption").innerText = latestCaption.text;
        }
      } catch (err) {
        console.error("Error fetching captions:", err);
      }
    }

    /**
     * Set up polling for both audio and caption endpoints.
     */
    function startPolling() {
      setInterval(() => {
        pollAudio();
        pollCaptions();
      }, pollInterval);
    }

    // Resume the AudioContext on user interaction (e.g., a click) since many browsers block audio autoplay.
    document.body.addEventListener('click', () => {
      if (audioContext.state === 'suspended') {
        audioContext.resume();
      }
    });

    // Start polling after the window loads.
    window.addEventListener('load', () => {
      startPolling();
    });
  </script>
</body>
</html>
